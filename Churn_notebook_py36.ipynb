{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "#from scikitplot.metrics import plot_lift_curve,plot_cumulative_gain #!pip install scikit-plot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {
    "1.png": {
     "image/png": "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"
    },
    "2.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAADoAAAA4CAYAAACsc+sjAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAADMSURBVGhD7ZNBCgIxEAT9mH/ybb4rVxG8RDxkKWEYNpsRobcL6jR9SMHupZ+E84U+ni85iUMVJA5VkDhUQeJQBYlDFSQOVZA4VEHiUAVJWej1dv9yz4ZG+1WJQ4+aPTy6ZftViUOPmj08umX7VcnP/tHhns1H7qokDlWQOHTW6HMcZjveqiUOnTV6eBaT3aokDp01engWk92qJH//R4fcVEkcqiBxqILEoQoShypIHKogcaiCxKEKEocqSByqINlCW2tyki1UHYdq0fsbRaXMkgP/FG0AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Ahora importe los datos para guardarlos como un \"Data frame\" y poder usarlos aquí en el Notebook. Primero debe dar click a la celda de abajo que se encuentra vacía. Luego abra el panel derecho dando click en el siguiente ícono que se encuentra arriba a la derecha:\n",
    "\n",
    "![2.PNG](attachment:2.PNG)\n",
    "\n",
    "Después que cargue deberá ver los archivos csv que previamente a cardagos. Busque \"Churn_Modeling.csv\", de click en \"Insert to code\" y luego \"Insert pandas DataFrame\"\n",
    "\n",
    "![1.png](attachment:1.png)\n",
    "\n",
    "\n",
    "Asegurate de que el data frame creado tenga el  nombre df_data_1, de lo contrario corrigelo.\n",
    "\n",
    "Corre la celda.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de taza de abandono de un banco tiene la particularidad de que del total de clientes solo un pequeño porcentaje es el que abandona el banco. En otras palabas, la variable \"Exited\" tiene muchos más \"0\" que \"1\". Para observar este comportamiento observemos la siguiente gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfica de variable a predecir\n",
    "churn_count=sns.countplot(df_data_1.Exited)\n",
    "churn_count.set(xlabel=\"¿El cliente abandonó el banco?\",ylabel=\"Número de clientes\",title=\"Distribución del abandono\")\n",
    "plt.show()\n",
    "\n",
    "print('Taza de abandono = ',str(100*sum(df_data_1.Exited==1)/len(df_data_1.Exited))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se van a hacer los últimos paso de procesamiento de datos. Primero debemos separar los datos en las\n",
    "matrices X,y. En \"X\" se guardan todas las variables que se van a usar para poder predecir y en \"y\"se guarda\n",
    "la variable \"Exited\" que es la que queremos predecir. \n",
    "\n",
    "Los aloritmos de machine learning no entienden bien cuando las variables son texto (Como es el caso de las variables \"Geography\" y \"Gender\". Para esto se usa una técnica llamada \"Label encoding\" que consiste en transformar cada palabra única de las variables a un número. Por ejemplo, en la variable \"Geography\" se podría convertir France a 1 y Spain a 2. \n",
    "\n",
    "Finalmente, se separan los datos en dos conjuntos: uno de entrenamiento y otro de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Se crean las matrices X,y.\n",
    "X=df_data_1.drop('Exited',axis=1)#Eliminamos columnas\n",
    "y=df_data_1.Exited#Definimos variable a predecir\n",
    "\n",
    "\n",
    "##Se define función que crea diccionarios para transformar los factores de las variables categóricas a números y viceversa.\n",
    "def label_encoder(X,cols):\n",
    "    from collections import namedtuple\n",
    "    encode={}\n",
    "    decode={}\n",
    "    for i in cols:\n",
    "        le=LabelEncoder()\n",
    "        le.fit_transform(X[i])\n",
    "        encode[i]=dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        decode[i]=dict(zip(le.transform(le.classes_),le.classes_))\n",
    "    encoder_tuple = namedtuple('encoder_tuple', ['encode', 'decode'])\n",
    "    dictionaries=encoder_tuple(encode,decode)\n",
    "    return(dictionaries)\n",
    "\n",
    "\n",
    "categoric=X.select_dtypes(include=['object']).columns#Guarda el nombre de las columnas categóricas.\n",
    "\n",
    "dictionaries=label_encoder(X,categoric)#Label encoder dictionaries\n",
    "X.replace(dictionaries.encode,inplace=True)#Codificamos las variables categóricas.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=0)#Dividimos los datos en entrenamiento y prueba.\n",
    "\n",
    "m,n=X_train.shape#Extraemos las dimensiones de la matriz X de entrenamiento.\n",
    "\n",
    "X.head()#Observamos cómo quedan las primeras 5 filas luego de la transformación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se corre el algoritmo que determinará el modelo.\n",
    "\n",
    "Los modelos de machine learning requieren de ciertos parámetros que el usuario debe ingresar. Sin embargo, hacer esto a mano no es nada práctico por lo que existen diferentes métodos para \"automatizar\" el proceso.\n",
    "El método usado a continuación se llama \"búsqueda aleatoria\". Para esto simplemente se seleccionan los parámetros que se quieren sintonizar y se establecen rangos de valores en los que se quieren que estén los parámetros. El valor que toma cada variable es tomado aleatoriamente de este este rango en cada iteración.\n",
    "\n",
    "Finalmente, se calcula la exactitud de los diferentes modelos y se escogen los parámetros del modelo con mejor exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_features\": sp_randint(int(np.sqrt(n)), int(3*n/4)),\n",
    "              \"min_samples_leaf\": sp_randint(1, 20)}#Se definen los hiperparámetros para sintonizar el modelo\n",
    "\n",
    "clf= RandomForestClassifier(n_jobs=-1,n_estimators=#COLOCAR AQUÍ NÚMERO DE ÁRBOLES) #Se inicializa la instancia de Random Forest.\n",
    "\n",
    "#Corre búsqueda aleatorio por X iteraciones.\n",
    "n_iter_search = #COLOQUE AQUÍ EL NÚMERO DE ITERACIONES\n",
    "random_search_clf= RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,cv=5,scoring=\"accuracy\",random_state=10)\n",
    "\n",
    "random_search_clf.fit(X_train, y_train)#Se entrena el modelo con los mejores parámetros encontrados.\n",
    "\n",
    "best_estimator=random_search_clf.best_estimator_#Guarda el modelo.\n",
    "best_score=random_search_clf.best_score_#Guarda el puntaje del mejor modelo\n",
    "\n",
    "print(' Best params:',best_estimator,'\\n','Best score:',best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que el modelo está entrenado, procedemos a probarlo en el conjunto de prueba.\n",
    "Para esto realizamos las predicciones de estos datos y luego comparamos con los resultados reales.\n",
    "Esta comparación se hace de acuerdo a varias métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=best_estimator.predict(X_test)#Predicciones binarias en el conjunto de prueba\n",
    "y_pred_proba=best_estimator.predict_proba(X_test)#Predicciones de probabilidad en el conjunto de prueba\n",
    "\n",
    "accuracy=accuracy_score(y_pred=y_pred,y_true=y_test)#Exactitud\n",
    "AUC=roc_auc_score(y_score=y_pred_proba[:,1],y_true=y_test)#AUC\n",
    "average_precision_score=  average_precision_score(y_true=y_test,y_score=y_pred_proba[:,1])\n",
    "\n",
    "print('Accuracy:'+str(np.round(accuracy*100,4))+\"%\",\"\\t\",'AUC:'+str(np.round(AUC*100,4))+\"%\",\"\\t\"\n",
    "     ,'average_precision_score:'+str(np.round(average_precision_score*100,4))+\"%\",\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear un API del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan los respositorios de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardan las credenciales del servicio de machine learning en un JSON para luego usar esta información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se autentica el servicio con las credenciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient( wml_credentials )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo en la instancia del servicio de machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "client.repository.DefinitionMetaNames.NAME              : \"**DALE UN NOMBRE AL MODELO**\",\n",
    "client.repository.DefinitionMetaNames.FRAMEWORK_NAME    : \"scikit-learn\",\n",
    "client.repository.DefinitionMetaNames.RUNTIME_NAME      : \"python\",\n",
    "client.repository.DefinitionMetaNames.RUNTIME_VERSION   : \"3.6\"\n",
    "}\n",
    "\n",
    "stored_model_details = client.repository.store_model(best_estimator,meta_props=metadata)\n",
    "print( \"stored_model_details: \", stored_model_details )\n",
    "model_uid            = client.repository.get_model_uid( stored_model_details )\n",
    "print( \"model_uid: \", model_uid )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Despliegue del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploymnt_name   = \"**DALE UN NOMBRE AL DESPLIEGUE**\"\n",
    "deployment_desc  = \"Online deployment of Python client tutorial model\"\n",
    "deployment       = client.deployments.create( model_uid, deploymnt_name, deployment_desc )\n",
    "scoring_endpoint = client.deployments.get_scoring_url( deployment )\n",
    "print( \"scoring_endpoint: \", scoring_endpoint )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autenticación al API de Watson Machine Learning\n",
    "\n",
    "Para poder acceder al REST API de Watson Machine Learning requerimos un token de acceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "# Paste your Watson Machine Learning service apikey here\n",
    "# Use the rest of the code sample as written\n",
    "apikey = wml_credentials['apikey']\n",
    "\n",
    "# Get an IAM token from IBM Cloud\n",
    "url     = \"https://iam.bluemix.net/oidc/token\"\n",
    "headers = { \"Content-Type\" : \"application/x-www-form-urlencoded\" }\n",
    "data    = \"apikey=\" + apikey + \"&grant_type=urn:ibm:params:oauth:grant-type:apikey\"\n",
    "IBM_cloud_IAM_uid = \"bx\"\n",
    "IBM_cloud_IAM_pwd = \"bx\"\n",
    "response  = requests.post( url, headers=headers, data=data, auth=( IBM_cloud_IAM_uid, IBM_cloud_IAM_pwd ) )\n",
    "iam_token = response.json()[\"access_token\"]\n",
    "header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + iam_token, 'ML-Instance-ID': wml_credentials['instance_id']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos realizar el llamado online del modelo publicado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a probar el modelo con datos de prueba ingresados por ustedes. Corra la siguiente celda y llene las celdas que se le solicitan\n",
    "que son necesarias para realizar la predicción. Esta celda guarda estos valores y los pre-procesa para que pueda ser usado por el modelo. Se genera un JSON que será la entrada al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credit_score=int(input(\"Credit score: \"))\n",
    "Geography=input(\"Geography: \")\n",
    "Gender=input(\"Gender: \")\n",
    "Age=int(input(\"Age: \"))\n",
    "Tenure=int(input(\"Tenure: \"))\n",
    "Balance=int(input(\"Balance: \"))\n",
    "Num_products=int(input(\"Number of products: \"))\n",
    "HasCrCard=input(\"Has credit card: \")\n",
    "IsActiveMember=input(\"Is active member: \")\n",
    "EstimadedSalary=int(input(\"Estimated salary\"))\n",
    "\n",
    "\n",
    "\n",
    "new_observation=np.array([[Credit_score,Geography,Gender,Age,Tenure,Balance,Num_products,HasCrCard,IsActiveMember,EstimadedSalary]],dtype=object)\n",
    "new_observation=pd.DataFrame(new_observation,columns=X.columns)\n",
    "new_observation.replace(dictionaries.encode,inplace=True)\n",
    "\n",
    "#Revisar la implementacion del API en el modelo desplegado en nuestro Proyecto.\n",
    "payload_scoring = {\"fields\": [\"CreditScore\", \"Geography\", \"Gender\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\", \"HasCrCard\", \"IsActiveMember\", \"EstimatedSalary\"], \"values\": [list(new_observation.values[0])]}\n",
    "print(payload_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al correr la celda de abajo se está ingresando el JSON anteriormente generado y se está haciendo el request a la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_scoring=requests.post(scoring_endpoint,json=payload_scoring,headers=header)\n",
    "response=json.loads(response_scoring.text)\n",
    "probabilidad_abandono=response['values'][0][1][1]\n",
    "print(\"Este cliente tiene una probabilidad de\",np.round(probabilidad_abandono,2),\"de abandonar el banco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Sección adicional si queda tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift(y_true,y_pred,percentile,expected_response_rate):\n",
    "    \n",
    "    n=int(np.round(len(y_true)*percentile))\n",
    "    y_true=y_true.astype(int)\n",
    "    \n",
    "    temp=pd.DataFrame({'y_pred': y_pred[:,1], 'y_true': y_true})\n",
    "    temp=temp.sort_values(by='y_pred',ascending=False).iloc[0:n,:]\n",
    "    \n",
    "    response_rate=sum(temp.y_true)/len(temp.y_true)\n",
    "    lift=response_rate/expected_response_rate\n",
    "    \n",
    "    return(lift)\n",
    "\n",
    "percentile=0.1\n",
    "expected_response_rate=0.2\n",
    "\n",
    "uplift_score=make_scorer(uplift,greater_is_better=True,needs_proba=True,percentile=percentile,expected_response_rate=expected_response_rate)\n",
    "\n",
    "uplift_cv=np.mean(cross_val_score(best_estimator,X_train,y_train.astype(int),cv=5,scoring=uplift_score))\n",
    "\n",
    "print('Cross validation uplift:',uplift_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lift and gain cumulative gain charts\n",
    "\n",
    "y_pred=best_estimator.predict_proba(X_test)\n",
    "print(uplift(y_pred=y_pred,y_true=y_test,percentile=percentile,expected_response_rate=expected_response_rate))\n",
    "\n",
    "plot_cumulative_gain(y_test, y_pred, title='Cumulative Gains Curve')\n",
    "plt.show()\n",
    "\n",
    "plot_lift_curve(y_test, y_pred, title='Lift curve')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
